
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Graph-Break Registry</title>
    <style>
        /* Basic Tailwind-like styles for demonstration */
        body { font-family: Arial, sans-serif; margin: 0; padding: 0; background-color: #f8f8f8; color: #333; }
        .container { max-width: 800px; margin: 20px auto; padding: 20px; background-color: #fff; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
        h1 { color: #333; }
        ul { list-style: none; padding: 0; }
        li { margin-bottom: 10px; border-bottom: 1px solid #eee; padding-bottom: 10px; }
        a { color: #007bff; text-decoration: none; }
        a:hover { text-decoration: underline; }
        .search-input { width: 100%; padding: 8px; margin-bottom: 15px; border: 1px solid #ccc; border-radius: 4px; }
        .text-sm { font-size: 0.875rem; }
        .text-gray-500 { color: #6b7280; }
        .italic { font-style: italic; }
        .font-bold { font-weight: bold; }
        pre { background-color: #eee; padding: 10px; border-radius: 4px; overflow-x: auto; }
    </style>
</head>
<body>
    <div class="container">
        <h1>Graph-Break Registry</h1>
        <p class="text-sm text-gray-500 mb-4">Below are all known graph breaks detected by&nbsp;Dynamo.</p>

        <!-- Search input - will require JS for functionality -->
        <input type="text" placeholder="Search GBID, type, explanation..." class="search-input" id="search-input">

        <ul id="registry-list">

            <li data-gbid="GB0000" data-type="All __torch_function__ overrides returned NotImplemented due to TypeError from user code" data-explanation="All __torch_function__ overrides for for function {fn} returned NotImplemented">
                <a href="/gb/gb0000">GB0000</a> —
                All __torch_function__ overrides returned NotImplemented due to TypeError from user code
            </li>

            <li data-gbid="GB0001" data-type="Argument of `as_subclass` must be a non-dispatcher-style tensor subclass" data-explanation="Currently not supported">
                <a href="/gb/gb0001">GB0001</a> —
                Argument of `as_subclass` must be a non-dispatcher-style tensor subclass
            </li>

            <li data-gbid="GB0002" data-type="Assertion failed on symbolic shapes" data-explanation="">
                <a href="/gb/gb0002">GB0002</a> —
                Assertion failed on symbolic shapes
            </li>

            <li data-gbid="GB0003" data-type="Attempt to trace generator" data-explanation="Generators cannot be compiled directly with `torch.compile`.">
                <a href="/gb/gb0003">GB0003</a> —
                Attempt to trace generator
            </li>

            <li data-gbid="GB0004" data-type="Attempted super().__delattr__() on an object without mutation tracking" data-explanation="Dynamo needs to track mutations on an object before `super().__delattr__` can be used on it. But the object ({self.objvar}) doesn't have attribute mutation tracking enabled.">
                <a href="/gb/gb0004">GB0004</a> —
                Attempted super().__delattr__() on an object without mutation tracking
            </li>

            <li data-gbid="GB0005" data-type="Attempted to a str() method implemented in C/C++" data-explanation="{type(arg.value)} has a C/C++ based str method. This is not supported.">
                <a href="/gb/gb0005">GB0005</a> —
                Attempted to a str() method implemented in C/C++
            </li>

            <li data-gbid="GB0006" data-type="Attempted to call a super() attribute that is not a function or method" data-explanation="Dynamo does not know how to trace the call `super().{name}()` because `super().{name}` is not a function or method attribute.">
                <a href="/gb/gb0006">GB0006</a> —
                Attempted to call a super() attribute that is not a function or method
            </li>

            <li data-gbid="GB0007" data-type="Attempted to call function marked as skipped" data-explanation="explanation">
                <a href="/gb/gb0007">GB0007</a> —
                Attempted to call function marked as skipped
            </li>

            <li data-gbid="GB0008" data-type="Attempted to inline function marked as skipped" data-explanation="Dynamo developers have intentionally marked that the function `{fn_qualname}` should not be traced.">
                <a href="/gb/gb0008">GB0008</a> —
                Attempted to inline function marked as skipped
            </li>

            <li data-gbid="GB0009" data-type="Attempted to inline function marked as skipped (SkipFunctionVariable)" data-explanation="Attempted to inline a function that was previously determined to be marked as intentionally skipped.">
                <a href="/gb/gb0009">GB0009</a> —
                Attempted to inline function marked as skipped (SkipFunctionVariable)
            </li>

            <li data-gbid="GB0010" data-type="Attempted to read a deleted variable" data-explanation="">
                <a href="/gb/gb0010">GB0010</a> —
                Attempted to read a deleted variable
            </li>

            <li data-gbid="GB0011" data-type="Attempted to read undefined local variable" data-explanation="Could not find a local variable with name `{name}`">
                <a href="/gb/gb0011">GB0011</a> —
                Attempted to read undefined local variable
            </li>

            <li data-gbid="GB0012" data-type="Attempted to read undefined local variable (implicit)" data-explanation="Could not find an implicit local variable with name `{name}`">
                <a href="/gb/gb0012">GB0012</a> —
                Attempted to read undefined local variable (implicit)
            </li>

            <li data-gbid="GB0013" data-type="Attempted to represent unregistered RemovableHandle" data-explanation="Dynamo attempted to build a representation of a torch.utils.hooks.RemovableHandle, which is not supported. This happens because the RemovableHandle was created in another frame.">
                <a href="/gb/gb0013">GB0013</a> —
                Attempted to represent unregistered RemovableHandle
            </li>

            <li data-gbid="GB0014" data-type="Attempted to wrap RNN, GRU, or LSTM" data-explanation="Dynamo does not support RNN, GRU, or LSTM.">
                <a href="/gb/gb0014">GB0014</a> —
                Attempted to wrap RNN, GRU, or LSTM
            </li>

            <li data-gbid="GB0015" data-type="Attempted to wrap sparse Tensor" data-explanation="torch.compile does not support sparse Tensors">
                <a href="/gb/gb0015">GB0015</a> —
                Attempted to wrap sparse Tensor
            </li>

            <li data-gbid="GB0016" data-type="Attempted to wrap strided NestedTensor" data-explanation="torch.compile does not support strided NestedTensor">
                <a href="/gb/gb0016">GB0016</a> —
                Attempted to wrap strided NestedTensor
            </li>

            <li data-gbid="GB0017" data-type="Attempted to wrap torch._higher_order_ops.invoke_subgraph" data-explanation="Directly using invoke_subgraph is not supported. Use nested_compile_region">
                <a href="/gb/gb0017">GB0017</a> —
                Attempted to wrap torch._higher_order_ops.invoke_subgraph
            </li>

            <li data-gbid="GB0018" data-type="Attempted to wrap unbacked SymInt" data-explanation="Unbacked SymInt input is not supported yet.">
                <a href="/gb/gb0018">GB0018</a> —
                Attempted to wrap unbacked SymInt
            </li>

            <li data-gbid="GB0019" data-type="AutogradFunctionContextVariable escaped Dynamo-traced region" data-explanation="We cannot reconstruct a torch.autograd.Function's context object.">
                <a href="/gb/gb0019">GB0019</a> —
                AutogradFunctionContextVariable escaped Dynamo-traced region
            </li>

            <li data-gbid="GB0020" data-type="BUILD_STRING key conflict" data-explanation="Failed to build format string due to key conflict">
                <a href="/gb/gb0020">GB0020</a> —
                BUILD_STRING key conflict
            </li>

            <li data-gbid="GB0021" data-type="BUILD_STRING type error" data-explanation="Format string part type is not correct - expected constant or format string.">
                <a href="/gb/gb0021">GB0021</a> —
                BUILD_STRING type error
            </li>

            <li data-gbid="GB0022" data-type="Bad import result" data-explanation="Import result is not a Python module.">
                <a href="/gb/gb0022">GB0022</a> —
                Bad import result
            </li>

            <li data-gbid="GB0023" data-type="Builtin `operator.*` comparison with constant `self` failed" data-explanation=""Failed to compare {self} with {other}, "                     + f"because {other} is not a Python constant or its mutation check fails."">
                <a href="/gb/gb0023">GB0023</a> —
                Builtin `operator.*` comparison with constant `self` failed
            </li>

            <li data-gbid="GB0024" data-type="CLEANUP_THROW with StopIteration" data-explanation="Received StopIteration when handling generator.throw/close. This is not supported.">
                <a href="/gb/gb0024">GB0024</a> —
                CLEANUP_THROW with StopIteration
            </li>

            <li data-gbid="GB0025" data-type="Call to `torch._dynamo.graph_break()`" data-explanation="User-inserted graph break. Message: {graph_break_msg}">
                <a href="/gb/gb0025">GB0025</a> —
                Call to `torch._dynamo.graph_break()`
            </li>

            <li data-gbid="GB0026" data-type="Calling subclass default constructor with more than tensor argument" data-explanation="Currently not supported">
                <a href="/gb/gb0026">GB0026</a> —
                Calling subclass default constructor with more than tensor argument
            </li>

            <li data-gbid="GB0027" data-type="Cannot check Tensor object identity without its fake value" data-explanation="TensorVariable is missing a fake example_value.">
                <a href="/gb/gb0027">GB0027</a> —
                Cannot check Tensor object identity without its fake value
            </li>

            <li data-gbid="GB0028" data-type="Caught non-Exception value" data-explanation="Except expects to receive an object of Exception type but received {exc_instance}.">
                <a href="/gb/gb0028">GB0028</a> —
                Caught non-Exception value
            </li>

            <li data-gbid="GB0029" data-type="Compilation of intermediate hooks requires compiled autograd" data-explanation="Dynamo must be in compiled_autograd to register hooks.">
                <a href="/gb/gb0029">GB0029</a> —
                Compilation of intermediate hooks requires compiled autograd
            </li>

            <li data-gbid="GB0030" data-type="ComptimeContext graph break" data-explanation="Manually triggered ComptimeContext graph break with message {msg}.">
                <a href="/gb/gb0030">GB0030</a> —
                ComptimeContext graph break
            </li>

            <li data-gbid="GB0031" data-type="Custom __getattribute__ in nn.Module attribute access" data-explanation="Dynamo does not support checking key existence on `nn.Module` instances that have a custom `__getattribute__` method defined.">
                <a href="/gb/gb0031">GB0031</a> —
                Custom __getattribute__ in nn.Module attribute access
            </li>

            <li data-gbid="GB0032" data-type="Custom __getattribute__ in nn.Module dict key check" data-explanation="Dynamo does not support checking key existence on `nn.Module` instances that have a custom `__getattribute__` method defined.">
                <a href="/gb/gb0032">GB0032</a> —
                Custom __getattribute__ in nn.Module dict key check
            </li>

            <li data-gbid="GB0033" data-type="Data dependent operator" data-explanation="Operator `{cause.func}` has a non-Tensor output whose value is dependent on the data of Tensor inputs.">
                <a href="/gb/gb0033">GB0033</a> —
                Data dependent operator
            </li>

            <li data-gbid="GB0034" data-type="Data-dependent assertion failed (cannot compile partial graph)" data-explanation="Dynamo has determined when encountering a data-dependent assert failure that it should not compile the partial graph.">
                <a href="/gb/gb0034">GB0034</a> —
                Data-dependent assertion failed (cannot compile partial graph)
            </li>

            <li data-gbid="GB0035" data-type="Data-dependent branching with non-constant __bool__" data-explanation="Attempted to perform data-dependent branching on a user-defined object with a __bool__ method that did not return a constant.">
                <a href="/gb/gb0035">GB0035</a> —
                Data-dependent branching with non-constant __bool__
            </li>

            <li data-gbid="GB0036" data-type="Dynamic shape operator" data-explanation="Operator `{cause.func}`'s output shape depends on input Tensor data.">
                <a href="/gb/gb0036">GB0036</a> —
                Dynamic shape operator
            </li>

            <li data-gbid="GB0037" data-type="Dynamic shape operator (no meta kernel)" data-explanation="Operator `{cause.func}` does not have a meta kernel that supports dynamic output shapes">
                <a href="/gb/gb0037">GB0037</a> —
                Dynamic shape operator (no meta kernel)
            </li>

            <li data-gbid="GB0038" data-type="Dynamic slicing with Tensor arguments" data-explanation="Creating slices with Tensor arguments is not supported. e.g. `l[:x]`, where `x` is a 1-element tensor.">
                <a href="/gb/gb0038">GB0038</a> —
                Dynamic slicing with Tensor arguments
            </li>

            <li data-gbid="GB0039" data-type="Dynamo cache limit exceeded" data-explanation="Dynamo attempted to recompile the code object too many times, exceeding the {limit_type} cache size limit.Giving up on compiling as the compile time tradeoff is likely not worth the performance gain.">
                <a href="/gb/gb0039">GB0039</a> —
                Dynamo cache limit exceeded
            </li>

            <li data-gbid="GB0040" data-type="Encountered aliasing during higher order op tracing" data-explanation="Higher order ops do not support aliasing. Found in {source_target.name()}">
                <a href="/gb/gb0040">GB0040</a> —
                Encountered aliasing during higher order op tracing
            </li>

            <li data-gbid="GB0041" data-type="Encountered input mutation during higher order op tracing" data-explanation="Higher order ops do not support input mutation. Found in {source_target.name()}">
                <a href="/gb/gb0041">GB0041</a> —
                Encountered input mutation during higher order op tracing
            </li>

            <li data-gbid="GB0042" data-type="Encountered non user function variable during invoke_subgraph HOP tracing" data-explanation="invoke_subgraph does not support non user function variable">
                <a href="/gb/gb0042">GB0042</a> —
                Encountered non user function variable during invoke_subgraph HOP tracing
            </li>

            <li data-gbid="GB0043" data-type="Encountered non-PT2-compliant op" data-explanation="msg +   + err_epilogue">
                <a href="/gb/gb0043">GB0043</a> —
                Encountered non-PT2-compliant op
            </li>

            <li data-gbid="GB0044" data-type="Encountered strided NestedTensor in automatic dynamic dim determination" data-explanation="torch.compile does not support strided NestedTensor">
                <a href="/gb/gb0044">GB0044</a> —
                Encountered strided NestedTensor in automatic dynamic dim determination
            </li>

            <li data-gbid="GB0045" data-type="Encountered tensor.is_inference() during tracing" data-explanation="tensor.is_inference() is not supported">
                <a href="/gb/gb0045">GB0045</a> —
                Encountered tensor.is_inference() during tracing
            </li>

            <li data-gbid="GB0046" data-type="Encountered torch.is_inference_mode_enabled during tracing" data-explanation="torch.is_inference_mode_enabled() is not supported">
                <a href="/gb/gb0046">GB0046</a> —
                Encountered torch.is_inference_mode_enabled during tracing
            </li>

            <li data-gbid="GB0047" data-type="Encountered unconverted argument when attempting to inline" data-explanation="An argument to an inlined function was not successfully converted to a VariableTracker.">
                <a href="/gb/gb0047">GB0047</a> —
                Encountered unconverted argument when attempting to inline
            </li>

            <li data-gbid="GB0048" data-type="Error getting associated real value" data-explanation="Dynamo encountered an error while trying to get the associated real value.">
                <a href="/gb/gb0048">GB0048</a> —
                Error getting associated real value
            </li>

            <li data-gbid="GB0049" data-type="Error when attempting to resolve op packet" data-explanation="str(e)">
                <a href="/gb/gb0049">GB0049</a> —
                Error when attempting to resolve op packet
            </li>

            <li data-gbid="GB0050" data-type="Exception with bad expected type" data-explanation="`except ...` has unsupported type {expected_exc_types}.">
                <a href="/gb/gb0050">GB0050</a> —
                Exception with bad expected type
            </li>

            <li data-gbid="GB0051" data-type="Exception with non-type expectation" data-explanation="`except ...` expects a non-type: {expected_type}.">
                <a href="/gb/gb0051">GB0051</a> —
                Exception with non-type expectation
            </li>

            <li data-gbid="GB0052" data-type="Excessive RestartAnalysis() calls" data-explanation="Dynamo attempted to trace the same frame 100+ times. Giving up on compiling as the compile time tradeoff is likely not worth the performance gain.">
                <a href="/gb/gb0052">GB0052</a> —
                Excessive RestartAnalysis() calls
            </li>

            <li data-gbid="GB0053" data-type="FSDP with use_orig_params=False" data-explanation="Dynamo only supports FSDP with use_orig_params=True">
                <a href="/gb/gb0053">GB0053</a> —
                FSDP with use_orig_params=False
            </li>

            <li data-gbid="GB0054" data-type="Failed to construct Enum variable" data-explanation="Attempted to construct an Enum value that is non-constant (e.g. int, string) or is not an acceptable value for the Enum. Acceptable values for Enum `{cls_type}`: {list(cls_type)}.">
                <a href="/gb/gb0054">GB0054</a> —
                Failed to construct Enum variable
            </li>

            <li data-gbid="GB0055" data-type="Failed to convert args/kwargs to proxy" data-explanation="Missing `as_proxy()` implementation for some arg/kwarg.">
                <a href="/gb/gb0055">GB0055</a> —
                Failed to convert args/kwargs to proxy
            </li>

            <li data-gbid="GB0056" data-type="Failed to mutate tensor data attribute" data-explanation="Dyanmo only supports mutating `.data` of tensor created outside `torch.compile` region">
                <a href="/gb/gb0056">GB0056</a> —
                Failed to mutate tensor data attribute
            </li>

            <li data-gbid="GB0057" data-type="Failed to raise exception" data-explanation="Attempted to raise a non-Exception type/value.">
                <a href="/gb/gb0057">GB0057</a> —
                Failed to raise exception
            </li>

            <li data-gbid="GB0058" data-type="Failed to set tensor attribute" data-explanation="Dyanmo doesn't support setting these tensor attributes">
                <a href="/gb/gb0058">GB0058</a> —
                Failed to set tensor attribute
            </li>

            <li data-gbid="GB0059" data-type="Failed to trace builtin operator" data-explanation="Dynamo does not know how to trace builtin operator `{fn.__name__}` with argument types {real_arg_types} (has_kwargs {has_kwargs})">
                <a href="/gb/gb0059">GB0059</a> —
                Failed to trace builtin operator
            </li>

            <li data-gbid="GB0060" data-type="Failed to trace unittest method" data-explanation="Dynamo does not know how to trace unittest method `{name}` ">
                <a href="/gb/gb0060">GB0060</a> —
                Failed to trace unittest method
            </li>

            <li data-gbid="GB0061" data-type="Failed to unpack object for BUILD_LIST_UNPACK" data-explanation="{seq} cannot be unpacked into a list for the BUILD_LIST_UNPACK bytecode (`[*x, *y, ...]`).">
                <a href="/gb/gb0061">GB0061</a> —
                Failed to unpack object for BUILD_LIST_UNPACK
            </li>

            <li data-gbid="GB0062" data-type="Failed to unpack object for UNPACK_EX" data-explanation="{seq} cannot be unpacked into a list for the UNPACK_EX bytecode.">
                <a href="/gb/gb0062">GB0062</a> —
                Failed to unpack object for UNPACK_EX
            </li>

            <li data-gbid="GB0063" data-type="Failed to unpack object for UNPACK_SEQUENCE" data-explanation="{seq} cannot be unpacked into a list for the UNPACK_SEQUENCE bytecode (i.e. `a, b, c = d`).">
                <a href="/gb/gb0063">GB0063</a> —
                Failed to unpack object for UNPACK_SEQUENCE
            </li>

            <li data-gbid="GB0064" data-type="Fake tensor propagation exception" data-explanation="msg">
                <a href="/gb/gb0064">GB0064</a> —
                Fake tensor propagation exception
            </li>

            <li data-gbid="GB0065" data-type="Graph break in inlined function" data-explanation="Graph breaks in an inlined call are not supported.">
                <a href="/gb/gb0065">GB0065</a> —
                Graph break in inlined function
            </li>

            <li data-gbid="GB0066" data-type="Graph break under GenericContextWrappingVariable" data-explanation="Attempted to graph break in an active context manager(s) that doesn't support graph breaking.">
                <a href="/gb/gb0066">GB0066</a> —
                Graph break under GenericContextWrappingVariable
            </li>

            <li data-gbid="GB0067" data-type="HigherOrderOperator: Mutating a variable not in the current scope (SideEffects)" data-explanation="This is not supported.">
                <a href="/gb/gb0067">GB0067</a> —
                HigherOrderOperator: Mutating a variable not in the current scope (SideEffects)
            </li>

            <li data-gbid="GB0068" data-type="Illegal method invocation in strict mode" data-explanation="Dynamo currently does not support this method ({name}) invocation in strict mode.">
                <a href="/gb/gb0068">GB0068</a> —
                Illegal method invocation in strict mode
            </li>

            <li data-gbid="GB0069" data-type="Import failure" data-explanation="Failure when attempting to import.">
                <a href="/gb/gb0069">GB0069</a> —
                Import failure
            </li>

            <li data-gbid="GB0070" data-type="Indexing list with non-scalar tensor" data-explanation="Attempted to index list-like object with tensor with > 1 element.">
                <a href="/gb/gb0070">GB0070</a> —
                Indexing list with non-scalar tensor
            </li>

            <li data-gbid="GB0071" data-type="Inline attempt with __self__" data-explanation="Attempted to inline a function with the `__self__` attribute. Dynamo is expected to decompose method calls into function calls with a `self` argument.">
                <a href="/gb/gb0071">GB0071</a> —
                Inline attempt with __self__
            </li>

            <li data-gbid="GB0072" data-type="Inplace op on input tensor" data-explanation="Attempted to trace an inplace view op on input tensor {typestr(self.value)}.">
                <a href="/gb/gb0072">GB0072</a> —
                Inplace op on input tensor
            </li>

            <li data-gbid="GB0073" data-type="Invoking an nn.Module inside a HigherOrderOperator" data-explanation="This is not supported.">
                <a href="/gb/gb0073">GB0073</a> —
                Invoking an nn.Module inside a HigherOrderOperator
            </li>

            <li data-gbid="GB0074" data-type="Invoking an nn.Module inside a higher order operator" data-explanation="This is not supported.">
                <a href="/gb/gb0074">GB0074</a> —
                Invoking an nn.Module inside a higher order operator
            </li>

            <li data-gbid="GB0075" data-type="LOAD_BUILD_CLASS bytecode not supported" data-explanation="Dynamo does not support tracing classes that are defined in the compiled region.">
                <a href="/gb/gb0075">GB0075</a> —
                LOAD_BUILD_CLASS bytecode not supported
            </li>

            <li data-gbid="GB0076" data-type="LOAD_FAST_CHECK on uninitialized variable" data-explanation="Attempted to load uninitialized local variable {inst.argval}">
                <a href="/gb/gb0076">GB0076</a> —
                LOAD_FAST_CHECK on uninitialized variable
            </li>

            <li data-gbid="GB0077" data-type="Length mismatch when unpacking object for UNPACK_SEQUENCE" data-explanation="{seq} unpacked to a list for the UNPACK_SEQUENCE bytecode (i.e. `a, b, c = d`) with unexpected length.">
                <a href="/gb/gb0077">GB0077</a> —
                Length mismatch when unpacking object for UNPACK_SEQUENCE
            </li>

            <li data-gbid="GB0078" data-type="Limitation of `nonstrict_trace" data-explanation="msg">
                <a href="/gb/gb0078">GB0078</a> —
                Limitation of `nonstrict_trace
            </li>

            <li data-gbid="GB0079" data-type="Missing CALL_INTRINSIC_1 handler" data-explanation="No handler implemented for CALL_INTRINSIC_1 {inst.argval} instruction.">
                <a href="/gb/gb0079">GB0079</a> —
                Missing CALL_INTRINSIC_1 handler
            </li>

            <li data-gbid="GB0080" data-type="Missing FakeTensor example value" data-explanation="`FakeTensor` example value was required for {node} but not available.">
                <a href="/gb/gb0080">GB0080</a> —
                Missing FakeTensor example value
            </li>

            <li data-gbid="GB0081" data-type="Missing attribute when running call_method node" data-explanation="make_error_message("attribute not defined")">
                <a href="/gb/gb0081">GB0081</a> —
                Missing attribute when running call_method node
            </li>

            <li data-gbid="GB0082" data-type="Missing bytecode handler" data-explanation="Dynamo does not know how to handle the bytecode instruction `{opname}`.">
                <a href="/gb/gb0082">GB0082</a> —
                Missing bytecode handler
            </li>

            <li data-gbid="GB0083" data-type="Module-level backwards hooks require compiled autograd." data-explanation="">
                <a href="/gb/gb0083">GB0083</a> —
                Module-level backwards hooks require compiled autograd.
            </li>

            <li data-gbid="GB0084" data-type="Non-constant attribute given to `super().__delattr__()`" data-explanation="Dynamo requires the attribute name passed to `super().__delattr__(...)` to be a constant (string).">
                <a href="/gb/gb0084">GB0084</a> —
                Non-constant attribute given to `super().__delattr__()`
            </li>

            <li data-gbid="GB0085" data-type="Non-function or method in subclass of torch.autograd.Function" data-explanation="Dynamo requires the `forward` attribute of a `torch.autograd.Function` subclass to be a standard Python function or method. Found type `{type(fn).__name__}` instead.">
                <a href="/gb/gb0085">GB0085</a> —
                Non-function or method in subclass of torch.autograd.Function
            </li>

            <li data-gbid="GB0086" data-type="Not a Python constant" data-explanation="Failed to convert {self} into a Python constant.">
                <a href="/gb/gb0086">GB0086</a> —
                Not a Python constant
            </li>

            <li data-gbid="GB0087" data-type="NotImplementedError/UnsupportedFakeTensorException when running FX node" data-explanation="make_error_message(e)">
                <a href="/gb/gb0087">GB0087</a> —
                NotImplementedError/UnsupportedFakeTensorException when running FX node
            </li>

            <li data-gbid="GB0088" data-type="Observed exception" data-explanation="observed_exn_gb_explanation">
                <a href="/gb/gb0088">GB0088</a> —
                Observed exception
            </li>

            <li data-gbid="GB0089" data-type="Observed exception (EXCEPT_HANDLER)" data-explanation="observed_exn_gb_explanation                                 + " This graph break is unexpected."">
                <a href="/gb/gb0089">GB0089</a> —
                Observed exception (EXCEPT_HANDLER)
            </li>

            <li data-gbid="GB0090" data-type="Operator does not support running with fake tensors" data-explanation="">
                <a href="/gb/gb0090">GB0090</a> —
                Operator does not support running with fake tensors
            </li>

            <li data-gbid="GB0091" data-type="Read uninitialized cell" data-explanation="Attempted to read a cell variable that has not been populated yet.">
                <a href="/gb/gb0091">GB0091</a> —
                Read uninitialized cell
            </li>

            <li data-gbid="GB0092" data-type="Reconstruction failure" data-explanation="Dynamo has no bytecode reconstruction implemented for sourceless variable {value}.">
                <a href="/gb/gb0092">GB0092</a> —
                Reconstruction failure
            </li>

            <li data-gbid="GB0093" data-type="Reconstruction failure: source.reconstruct not implemented" data-explanation="Dynamo has no bytecode reconstruction implemented for {type(source)} variable {source}.">
                <a href="/gb/gb0093">GB0093</a> —
                Reconstruction failure: source.reconstruct not implemented
            </li>

            <li data-gbid="GB0094" data-type="SEND with bad type" data-explanation="Attempted to SEND with unsupported type {typestr(tos)}.">
                <a href="/gb/gb0094">GB0094</a> —
                SEND with bad type
            </li>

            <li data-gbid="GB0095" data-type="Set Exception object `__traceback__` attribute to not-`None`" data-explanation="Dynamo does not support setting the attribute '__traceback__' on tracked exception objects to anything other than None.">
                <a href="/gb/gb0095">GB0095</a> —
                Set Exception object `__traceback__` attribute to not-`None`
            </li>

            <li data-gbid="GB0096" data-type="Should not compile partial graph (STORE_ATTR)" data-explanation="Dynamo has determined when encountering an unsupported STORE_ATTR instruction (i.e. `obj.attr = val`) that it should not compile the partial graph.">
                <a href="/gb/gb0096">GB0096</a> —
                Should not compile partial graph (STORE_ATTR)
            </li>

            <li data-gbid="GB0097" data-type="Side effect on existing deque with limited maxlen" data-explanation="This is not supported.">
                <a href="/gb/gb0097">GB0097</a> —
                Side effect on existing deque with limited maxlen
            </li>

            <li data-gbid="GB0098" data-type="Skip calling `torch.compiler.disable()`d function" data-explanation="Skip calling function `{self.value}` since it was wrapped with `torch.compiler.disable` (reason: {msg})">
                <a href="/gb/gb0098">GB0098</a> —
                Skip calling `torch.compiler.disable()`d function
            </li>

            <li data-gbid="GB0099" data-type="Skip inlining `torch.compiler.disable()`d function" data-explanation="Skip inlining function {func.get_function()} since it was wrapped with `torch.compiler.disable` (reason: {msg})">
                <a href="/gb/gb0099">GB0099</a> —
                Skip inlining `torch.compiler.disable()`d function
            </li>

            <li data-gbid="GB0100" data-type="Storing Tensor hook handle in globals" data-explanation="This is not supported.">
                <a href="/gb/gb0100">GB0100</a> —
                Storing Tensor hook handle in globals
            </li>

            <li data-gbid="GB0101" data-type="Storing Tensor hook handle in globals (inline call)" data-explanation="This is not supported.">
                <a href="/gb/gb0101">GB0101</a> —
                Storing Tensor hook handle in globals (inline call)
            </li>

            <li data-gbid="GB0102" data-type="Strict mode banned op" data-explanation="Getattr invocation '{name}' in strict mode is not supported.">
                <a href="/gb/gb0102">GB0102</a> —
                Strict mode banned op
            </li>

            <li data-gbid="GB0103" data-type="Tensor subclass overridden method call" data-explanation="`torch.compile` currently can't trace this">
                <a href="/gb/gb0103">GB0103</a> —
                Tensor subclass overridden method call
            </li>

            <li data-gbid="GB0104" data-type="Tensor with grad_fn()" data-explanation="Dynamo does not support tracing tensors with a grad_fn directly.">
                <a href="/gb/gb0104">GB0104</a> —
                Tensor with grad_fn()
            </li>

            <li data-gbid="GB0105" data-type="Tensor.numpy() with trace_numpy=False" data-explanation="`Tensor.numpy()` was called, but the `trace_numpy` configuration was manually disabled.">
                <a href="/gb/gb0105">GB0105</a> —
                Tensor.numpy() with trace_numpy=False
            </li>

            <li data-gbid="GB0106" data-type="Tensor.numpy() without NumPy installed" data-explanation="`Tensor.numpy()` was called, but the NumPy library is not available in the current environment.">
                <a href="/gb/gb0106">GB0106</a> —
                Tensor.numpy() without NumPy installed
            </li>

            <li data-gbid="GB0107" data-type="Tensor.random_ op" data-explanation="This is currently not supported.">
                <a href="/gb/gb0107">GB0107</a> —
                Tensor.random_ op
            </li>

            <li data-gbid="GB0108" data-type="Tensor.retain_grad() with AOTDispatcher" data-explanation="`Tensor.retain_grad()` does not work with AOTDispatcher.">
                <a href="/gb/gb0108">GB0108</a> —
                Tensor.retain_grad() with AOTDispatcher
            </li>

            <li data-gbid="GB0109" data-type="Tensor.tolist() with non-integer tensor" data-explanation="Dynamo currently does not support tracing `tolist()` on non-integer tensors.">
                <a href="/gb/gb0109">GB0109</a> —
                Tensor.tolist() with non-integer tensor
            </li>

            <li data-gbid="GB0110" data-type="Tensor.uniform_ op called with `from` keyword" data-explanation="This is currently not supported.">
                <a href="/gb/gb0110">GB0110</a> —
                Tensor.uniform_ op called with `from` keyword
            </li>

            <li data-gbid="GB0111" data-type="TypeError from user code" data-explanation="msg">
                <a href="/gb/gb0111">GB0111</a> —
                TypeError from user code
            </li>

            <li data-gbid="GB0112" data-type="TypeError when making fake tensor call" data-explanation="">
                <a href="/gb/gb0112">GB0112</a> —
                TypeError when making fake tensor call
            </li>

            <li data-gbid="GB0113" data-type="Unable to resolve super getattr" data-explanation="Dynamo failed to trace attribute `{name}` accessed via `super()` (for type `{self.typevar}` and object `{self.objvar}`) because the resolved attribute type is not supported.">
                <a href="/gb/gb0113">GB0113</a> —
                Unable to resolve super getattr
            </li>

            <li data-gbid="GB0114" data-type="Unexpected failure during itertools.accumulate() iteration" data-explanation="Unexpected failure in invoking function during accumulate. Failed running func {func}({item}{acc})">
                <a href="/gb/gb0114">GB0114</a> —
                Unexpected failure during itertools.accumulate() iteration
            </li>

            <li data-gbid="GB0115" data-type="Unexpected failure during itertools.groupby() iteration" data-explanation="Unexpected failure in invoking function during groupby">
                <a href="/gb/gb0115">GB0115</a> —
                Unexpected failure during itertools.groupby() iteration
            </li>

            <li data-gbid="GB0116" data-type="Unexpected type in sourceless builder" data-explanation="SourcelessBuilder.create does not know how to wrap {value_type}">
                <a href="/gb/gb0116">GB0116</a> —
                Unexpected type in sourceless builder
            </li>

            <li data-gbid="GB0117" data-type="Unhandled args for method" data-explanation="Dynamo encountered an error while calling the method `{name}`.">
                <a href="/gb/gb0117">GB0117</a> —
                Unhandled args for method
            </li>

            <li data-gbid="GB0118" data-type="Unimplemented next() call" data-explanation="This abstract method must be implemented">
                <a href="/gb/gb0118">GB0118</a> —
                Unimplemented next() call
            </li>

            <li data-gbid="GB0119" data-type="Uninitialized nn.Module" data-explanation="Attempted to trace an uninitialized nn.Module of type {typestr(value)}.">
                <a href="/gb/gb0119">GB0119</a> —
                Uninitialized nn.Module
            </li>

            <li data-gbid="GB0120" data-type="Unreachable sub-generator code" data-explanation="Should only be encountered while implementing generator support.">
                <a href="/gb/gb0120">GB0120</a> —
                Unreachable sub-generator code
            </li>

            <li data-gbid="GB0121" data-type="UnspecializedNNModuleVariable missing method" data-explanation="Dynamo does not support tracing method {name} of nn.Module {self.value}">
                <a href="/gb/gb0121">GB0121</a> —
                UnspecializedNNModuleVariable missing method
            </li>

            <li data-gbid="GB0122" data-type="Unsupported SourceType" data-explanation="Dynamo does not support the type `{typ}`">
                <a href="/gb/gb0122">GB0122</a> —
                Unsupported SourceType
            </li>

            <li data-gbid="GB0123" data-type="Unsupported Tensor.backward() call" data-explanation="Dynamo currently does not support tracing `Tensor.backward()`.">
                <a href="/gb/gb0123">GB0123</a> —
                Unsupported Tensor.backward() call
            </li>

            <li data-gbid="GB0124" data-type="Unsupported Tensor.item() call with capture_scalar_outputs=False" data-explanation="Dynamo does not support tracing `Tensor.item()` with config.capture_scalar_outputs=False.">
                <a href="/gb/gb0124">GB0124</a> —
                Unsupported Tensor.item() call with capture_scalar_outputs=False
            </li>

            <li data-gbid="GB0125" data-type="Unsupported Tensor.requires_grad_() call" data-explanation="Dynamo does not support changes to a Tensor's `requires_grad` through calling `requires_grad_()`.">
                <a href="/gb/gb0125">GB0125</a> —
                Unsupported Tensor.requires_grad_() call
            </li>

            <li data-gbid="GB0126" data-type="Unsupported Tensor.resize_() call" data-explanation="Dynamo currently does not support tracing `Tensor.resize_()`.">
                <a href="/gb/gb0126">GB0126</a> —
                Unsupported Tensor.resize_() call
            </li>

            <li data-gbid="GB0127" data-type="Unsupported Tensor.resize_as_() call" data-explanation="Dynamo currently does not support tracing `Tensor.resize_as_()`.">
                <a href="/gb/gb0127">GB0127</a> —
                Unsupported Tensor.resize_as_() call
            </li>

            <li data-gbid="GB0128" data-type="Unsupported Tensor.set_() call" data-explanation="Dynamo currently does not support tracing `Tensor.set_()` overloads that include more than one argument.">
                <a href="/gb/gb0128">GB0128</a> —
                Unsupported Tensor.set_() call
            </li>

            <li data-gbid="GB0129" data-type="Unsupported Tensor.sparse_resize_() call" data-explanation="Dynamo currently does not support tracing `Tensor.sparse_resize_()`.">
                <a href="/gb/gb0129">GB0129</a> —
                Unsupported Tensor.sparse_resize_() call
            </li>

            <li data-gbid="GB0130" data-type="Unsupported Tensor.sparse_resize_and_clear_() call" data-explanation="Dynamo currently does not support tracing `Tensor.sparse_resize_and_clear_()`.">
                <a href="/gb/gb0130">GB0130</a> —
                Unsupported Tensor.sparse_resize_and_clear_() call
            </li>

            <li data-gbid="GB0131" data-type="Unsupported __setitem__/__setattr__ inline attempt" data-explanation="Attempted to inline {code.co_name} where first argument (self) is not a user-defined object.">
                <a href="/gb/gb0131">GB0131</a> —
                Unsupported __setitem__/__setattr__ inline attempt
            </li>

            <li data-gbid="GB0132" data-type="Unsupported `func` in itertools.accumulate" data-explanation="Dynamo does not know how to get the function to use for itertools.accumulate. itertools.accumulate expects the `func` as the second argument or as a keyword argument.">
                <a href="/gb/gb0132">GB0132</a> —
                Unsupported `func` in itertools.accumulate
            </li>

            <li data-gbid="GB0133" data-type="Unsupported arguments for itertools.accumulate" data-explanation="Dynamo does not know how to trace itertools.accumulate with args: {args} and kwargs: {kwargs}. itertools.accumulate expects an iterable, an optional binary function for accumulation, and an optional initial value to set the starting state.">
                <a href="/gb/gb0133">GB0133</a> —
                Unsupported arguments for itertools.accumulate
            </li>

            <li data-gbid="GB0134" data-type="Unsupported arguments for itertools.groupby" data-explanation="Dynamo does not know how to trace itertools.groupby with args: {args} and kwargs: {kwargs}. itertools.groupby expects an iterable to group and an optional key function to determine groupings.">
                <a href="/gb/gb0134">GB0134</a> —
                Unsupported arguments for itertools.groupby
            </li>

            <li data-gbid="GB0135" data-type="Unsupported attribute assignment on Exception object" data-explanation="Dynamo does not support setting the attribute '{name}' on tracked exception objects. Only `__context__`, `__cause__`, `__suppress_context__`, and `__traceback__` are supported.">
                <a href="/gb/gb0135">GB0135</a> —
                Unsupported attribute assignment on Exception object
            </li>

            <li data-gbid="GB0136" data-type="Unsupported attribute for range() object" data-explanation="Expected attribute to be one of {','.join(fields)} but got {name}">
                <a href="/gb/gb0136">GB0136</a> —
                Unsupported attribute for range() object
            </li>

            <li data-gbid="GB0137" data-type="Unsupported attribute for slice() object" data-explanation="Expected attribute to be one of {','.join(fields)} but got {name}">
                <a href="/gb/gb0137">GB0137</a> —
                Unsupported attribute for slice() object
            </li>

            <li data-gbid="GB0138" data-type="Unsupported autograd.Function context `save_for_backward`" data-explanation="Dynamo requires the `saved_tensors` attribute to be initialized on the `autograd.Function` context object.">
                <a href="/gb/gb0138">GB0138</a> —
                Unsupported autograd.Function context `save_for_backward`
            </li>

            <li data-gbid="GB0139" data-type="Unsupported autograd.Function context method" data-explanation="Dynamo does not support calling the method `{name}` on `autograd.Function` context objects. Supported methods are `__setattr__`, `save_for_backward` and `mark_non_differentiable`.">
                <a href="/gb/gb0139">GB0139</a> —
                Unsupported autograd.Function context method
            </li>

            <li data-gbid="GB0140" data-type="Unsupported autograd.Function method" data-explanation="Dynamo does not support calling the method `{name}` directly on the `torch.autograd.Function` instance. Supported methods include `apply`, `backward`, static methods, and class methods.">
                <a href="/gb/gb0140">GB0140</a> —
                Unsupported autograd.Function method
            </li>

            <li data-gbid="GB0141" data-type="Unsupported call_id() without source" data-explanation="call_id() not supported for sourceless TensorVariable.">
                <a href="/gb/gb0141">GB0141</a> —
                Unsupported call_id() without source
            </li>

            <li data-gbid="GB0142" data-type="Unsupported context manager" data-explanation="Dynamo does not know how to enter a `{ctx.python_type_name()}` context manager.">
                <a href="/gb/gb0142">GB0142</a> —
                Unsupported context manager
            </li>

            <li data-gbid="GB0143" data-type="Unsupported conversion for slice assignment" data-explanation="Missing dynamo support for converting {value} into a list for slice assignment.">
                <a href="/gb/gb0143">GB0143</a> —
                Unsupported conversion for slice assignment
            </li>

            <li data-gbid="GB0144" data-type="Unsupported custom jvp" data-explanation="Dynamo does not support tracing `torch.autograd.Function` subclasses that define a custom `jvp` method.">
                <a href="/gb/gb0144">GB0144</a> —
                Unsupported custom jvp
            </li>

            <li data-gbid="GB0145" data-type="Unsupported custom vjp" data-explanation="Dynamo does not support tracing `torch.autograd.Function` subclasses that define a custom `vjp` method.">
                <a href="/gb/gb0145">GB0145</a> —
                Unsupported custom vjp
            </li>

            <li data-gbid="GB0146" data-type="Unsupported event method" data-explanation="Dynamo doesn't support tracing the {method_name} method. We currently support wait, record, synchronize, and query.">
                <a href="/gb/gb0146">GB0146</a> —
                Unsupported event method
            </li>

            <li data-gbid="GB0147" data-type="Unsupported function call" data-explanation="Dynamo does not know how to trace the function `{self.debug_repr()}`">
                <a href="/gb/gb0147">GB0147</a> —
                Unsupported function call
            </li>

            <li data-gbid="GB0148" data-type="Unsupported function call (delayed)" data-explanation="Dynamo determined that a graph break should occur when calling `{self.source.name()}`. Reason: {self.msg}">
                <a href="/gb/gb0148">GB0148</a> —
                Unsupported function call (delayed)
            </li>

            <li data-gbid="GB0149" data-type="Unsupported functorch tracing attempt" data-explanation="msg">
                <a href="/gb/gb0149">GB0149</a> —
                Unsupported functorch tracing attempt
            </li>

            <li data-gbid="GB0150" data-type="Unsupported hasattr call" data-explanation="Dynamo does not know how to trace the function `{self.debug_repr()}`">
                <a href="/gb/gb0150">GB0150</a> —
                Unsupported hasattr call
            </li>

            <li data-gbid="GB0151" data-type="Unsupported inspect call" data-explanation="Dynamo does not know how to trace the function `{self.debug_repr()}`">
                <a href="/gb/gb0151">GB0151</a> —
                Unsupported inspect call
            </li>

            <li data-gbid="GB0152" data-type="Unsupported key type for itertools.groupby" data-explanation="Dynamo does not know how to trace itertools.groupby with key type: {str(type(key))}. We only support grouping keys that are constants (int, float, str, etc.)">
                <a href="/gb/gb0152">GB0152</a> —
                Unsupported key type for itertools.groupby
            </li>

            <li data-gbid="GB0153" data-type="Unsupported key type for nn.Module.__getitem__" data-explanation="Dynamo does not support getitem on `nn.Module` with non-constant key.">
                <a href="/gb/gb0153">GB0153</a> —
                Unsupported key type for nn.Module.__getitem__
            </li>

            <li data-gbid="GB0154" data-type="Unsupported kwargs for itertools.accumulate" data-explanation="Expected kwargs: 'initial', 'func', but got {','.join(set(kwargs.keys()) - {'initial', 'func'})}">
                <a href="/gb/gb0154">GB0154</a> —
                Unsupported kwargs for itertools.accumulate
            </li>

            <li data-gbid="GB0155" data-type="Unsupported kwargs for itertools.groupby" data-explanation="Expected kwargs: 'key', but got {','.join(set(kwargs.keys()) - {'key'})}">
                <a href="/gb/gb0155">GB0155</a> —
                Unsupported kwargs for itertools.groupby
            </li>

            <li data-gbid="GB0156" data-type="Unsupported method call" data-explanation="Dynamo does not know how to trace method `{name}` of class `{self.python_type_name()}`">
                <a href="/gb/gb0156">GB0156</a> —
                Unsupported method call
            </li>

            <li data-gbid="GB0157" data-type="Unsupported ndarray attribute access" data-explanation="Dynamo currently does not support tracing `ndarray.{name}`.">
                <a href="/gb/gb0157">GB0157</a> —
                Unsupported ndarray attribute access
            </li>

            <li data-gbid="GB0158" data-type="Unsupported ndarray method call" data-explanation="`ndarray.{name}()` is not modelled in `torch._numpy`.">
                <a href="/gb/gb0158">GB0158</a> —
                Unsupported ndarray method call
            </li>

            <li data-gbid="GB0159" data-type="Unsupported ndarray.__version__ access" data-explanation="Dynamo currently does not support tracing `ndarray.{name}`.">
                <a href="/gb/gb0159">GB0159</a> —
                Unsupported ndarray.__version__ access
            </li>

            <li data-gbid="GB0160" data-type="Unsupported next() call" data-explanation="Dynamo does not know how to trace calling `next()` on variable `{self}`.">
                <a href="/gb/gb0160">GB0160</a> —
                Unsupported next() call
            </li>

            <li data-gbid="GB0161" data-type="Unsupported nn.Module attribute type" data-explanation="Dynamo does not support tracing nn.Module attributes of type `{typestr(subobj)}`">
                <a href="/gb/gb0161">GB0161</a> —
                Unsupported nn.Module attribute type
            </li>

            <li data-gbid="GB0162" data-type="Unsupported super().__init__() call" data-explanation="Dynamo encountered a super().__init__() call on {objvar} that resolved to a `torch.nn.Module.__init__()` call that we cannot trace.">
                <a href="/gb/gb0162">GB0162</a> —
                Unsupported super().__init__() call
            </li>

            <li data-gbid="GB0163" data-type="Unsupported tensor subclass attribute access" data-explanation="`torch.compile` currently can't trace this">
                <a href="/gb/gb0163">GB0163</a> —
                Unsupported tensor subclass attribute access
            </li>

            <li data-gbid="GB0164" data-type="Unsupported tensor subclass overridden attribute access" data-explanation="`torch.compile` only support tracing certain types of overridden tensor subclass attributes">
                <a href="/gb/gb0164">GB0164</a> —
                Unsupported tensor subclass overridden attribute access
            </li>

            <li data-gbid="GB0165" data-type="Unsupported torch._C._ImperativeEngine method" data-explanation="Dynamo only supports the `queue_callback` method on a torch._C._ImperativeEngine instance, but found: `{name}`.">
                <a href="/gb/gb0165">GB0165</a> —
                Unsupported torch._C._ImperativeEngine method
            </li>

            <li data-gbid="GB0166" data-type="Unsupported torch._C._ImperativeEngine.queue_callback()" data-explanation="queue_callback() is only supported when Compiled Autograd is enabled with fullgraph=True.">
                <a href="/gb/gb0166">GB0166</a> —
                Unsupported torch._C._ImperativeEngine.queue_callback()
            </li>

            <li data-gbid="GB0167" data-type="Variadic function call with bad args/kwargs type" data-explanation="Expected args to be a list and kwargs to be a dict">
                <a href="/gb/gb0167">GB0167</a> —
                Variadic function call with bad args/kwargs type
            </li>

            <li data-gbid="GB0168" data-type="Variadic function call with bad flags" data-explanation="Attempted to call a variadic function (CALL_FUNCTION_EX) with bad flags {inst.argval}">
                <a href="/gb/gb0168">GB0168</a> —
                Variadic function call with bad flags
            </li>

            <li data-gbid="GB0169" data-type="Write to immutable cell" data-explanation="Dynamo doesn't support writing to immutable/sourceless cell variables.">
                <a href="/gb/gb0169">GB0169</a> —
                Write to immutable cell
            </li>

            <li data-gbid="GB0170" data-type="Data-dependent branching" data-explanation="_explanation">
                <a href="/gb/gb0170">GB0170</a> —
                Data-dependent branching
            </li>

            <li data-gbid="GB0171" data-type="assert with non-string message" data-explanation="Dynamo only supports asserts with string messages">
                <a href="/gb/gb0171">GB0171</a> —
                assert with non-string message
            </li>

            <li data-gbid="GB0172" data-type="async_op=True for distributed collectives" data-explanation="`torch.compile` doesn't support `async_op=True for {self.fn}">
                <a href="/gb/gb0172">GB0172</a> —
                async_op=True for distributed collectives
            </li>

            <li data-gbid="GB0173" data-type="backward_state does not support export" data-explanation="Compiled autograd doesn't work with `torch.export`.">
                <a href="/gb/gb0173">GB0173</a> —
                backward_state does not support export
            </li>

            <li data-gbid="GB0174" data-type="bad args to builtin cast()" data-explanation="Dynamo expects exactly 2 args to builtin cast().">
                <a href="/gb/gb0174">GB0174</a> —
                bad args to builtin cast()
            </li>

            <li data-gbid="GB0175" data-type="builtin isinstance() cannot determine type of argument" data-explanation="Dynamo doesn't have a rule to determine the type of argument {arg}">
                <a href="/gb/gb0175">GB0175</a> —
                builtin isinstance() cannot determine type of argument
            </li>

            <li data-gbid="GB0176" data-type="call_id() without associated real value" data-explanation="Dynamo could not find an associated real value for the tensor.">
                <a href="/gb/gb0176">GB0176</a> —
                call_id() without associated real value
            </li>

            <li data-gbid="GB0177" data-type="can't handle functions not implemented in python " data-explanation="Dynamo can only handle functions defined in python">
                <a href="/gb/gb0177">GB0177</a> —
                can't handle functions not implemented in python 
            </li>

            <li data-gbid="GB0178" data-type="constant fold exception" data-explanation="Encountered exception when attempting to constant fold.">
                <a href="/gb/gb0178">GB0178</a> —
                constant fold exception
            </li>

            <li data-gbid="GB0179" data-type="copy.deepcopy()" data-explanation="Dynamo does not support copy.deepcopy()">
                <a href="/gb/gb0179">GB0179</a> —
                copy.deepcopy()
            </li>

            <li data-gbid="GB0180" data-type="dataclass fields failure" data-explanation="Dataclass fields handling fails for {obj}. Expected it to be a user-defined object.">
                <a href="/gb/gb0180">GB0180</a> —
                dataclass fields failure
            </li>

            <li data-gbid="GB0181" data-type="dtype mismatch between tensor and its gradient" data-explanation="Inconsistent dtype between tensor and its gradient. This can happen in FSDP and crashes meta tensor creation.">
                <a href="/gb/gb0181">GB0181</a> —
                dtype mismatch between tensor and its gradient
            </li>

            <li data-gbid="GB0182" data-type="failed to broadcast when attempting Tensor comparison op" data-explanation="Dynamo was unable to broad cast the arguments {left}, {right} when attempting to trace the comparison op {op.__name__}.">
                <a href="/gb/gb0182">GB0182</a> —
                failed to broadcast when attempting Tensor comparison op
            </li>

            <li data-gbid="GB0183" data-type="failed to call dict.fromkeys()" data-explanation="Failed to call {user_cls.__name__}.fromkeys() because arguments could not be automatically converted to a list, or some dict key is not hashable.">
                <a href="/gb/gb0183">GB0183</a> —
                failed to call dict.fromkeys()
            </li>

            <li data-gbid="GB0184" data-type="failed to call str() on user defined object" data-explanation="User defined object has no __str__ or __repr__ method">
                <a href="/gb/gb0184">GB0184</a> —
                failed to call str() on user defined object
            </li>

            <li data-gbid="GB0185" data-type="failed to convert numpy.ndarray to Tensor" data-explanation="Exception encountered when attempting to convert numpy.ndarray to Tensor">
                <a href="/gb/gb0185">GB0185</a> —
                failed to convert numpy.ndarray to Tensor
            </li>

            <li data-gbid="GB0186" data-type="functools.partial() with non-literal keyword" data-explanation="functools.partial() expects literal/string keywords">
                <a href="/gb/gb0186">GB0186</a> —
                functools.partial() with non-literal keyword
            </li>

            <li data-gbid="GB0187" data-type="functools.wraps" data-explanation="`torch.compile` can't trace `functools.wraps` on functions defined outside the compile region">
                <a href="/gb/gb0187">GB0187</a> —
                functools.wraps
            </li>

            <li data-gbid="GB0188" data-type="getattr with no source" data-explanation="Dynamo does not know how to access an attribute on an `nn.Module` instance that lacks a source. This is usually an internal error in Dynamo.">
                <a href="/gb/gb0188">GB0188</a> —
                getattr with no source
            </li>

            <li data-gbid="GB0189" data-type="getattr() on nn.Module with pending mutation" data-explanation="Intentionally graph breaking on getattr() on a nn.Module with a pending mutation">
                <a href="/gb/gb0189">GB0189</a> —
                getattr() on nn.Module with pending mutation
            </li>

            <li data-gbid="GB0190" data-type="getattr() with non-constant name argument" data-explanation="getattr() with non-constant name argument is not supported">
                <a href="/gb/gb0190">GB0190</a> —
                getattr() with non-constant name argument
            </li>

            <li data-gbid="GB0191" data-type="id() with unsupported args" data-explanation="Dynamo doesn't know how to trace id() call with args {args}">
                <a href="/gb/gb0191">GB0191</a> —
                id() with unsupported args
            </li>

            <li data-gbid="GB0192" data-type="input iterator to itertools.cycle has too many items" data-explanation="Has reached internal Dynamo max iterator limit: {MAX_ITERATOR_LIMIT}">
                <a href="/gb/gb0192">GB0192</a> —
                input iterator to itertools.cycle has too many items
            </li>

            <li data-gbid="GB0193" data-type="invalid call to builtin op handler" data-explanation="Encountered TypeError when trying to handle op {fn.__name__}">
                <a href="/gb/gb0193">GB0193</a> —
                invalid call to builtin op handler
            </li>

            <li data-gbid="GB0194" data-type="isinstance() called on user defined object with C extensions" data-explanation="User-defined object with C extensions can have torch.Tensor attributes; intentionally graph breaking.">
                <a href="/gb/gb0194">GB0194</a> —
                isinstance() called on user defined object with C extensions
            </li>

            <li data-gbid="GB0195" data-type="issubclass() with non-constant arguments" data-explanation="issubclass() with non-constant arguments not supported.">
                <a href="/gb/gb0195">GB0195</a> —
                issubclass() with non-constant arguments
            </li>

            <li data-gbid="GB0196" data-type="key not found in dict" data-explanation="msg">
                <a href="/gb/gb0196">GB0196</a> —
                key not found in dict
            </li>

            <li data-gbid="GB0197" data-type="list elements are pointing to the list itself" data-explanation="Dynamo does not support lists whose items reference to itself">
                <a href="/gb/gb0197">GB0197</a> —
                list elements are pointing to the list itself
            </li>

            <li data-gbid="GB0198" data-type="mapping proxy affected by dictionary mutation" data-explanation="msg">
                <a href="/gb/gb0198">GB0198</a> —
                mapping proxy affected by dictionary mutation
            </li>

            <li data-gbid="GB0199" data-type="mapping proxy cannot be reconstructed" data-explanation="msg">
                <a href="/gb/gb0199">GB0199</a> —
                mapping proxy cannot be reconstructed
            </li>

            <li data-gbid="GB0200" data-type="missing BUILD_SET handler" data-explanation="Missing BUILD_SET bytecode handler (for testing purposes).">
                <a href="/gb/gb0200">GB0200</a> —
                missing BUILD_SET handler
            </li>

            <li data-gbid="GB0201" data-type="namedtuple construction" data-explanation="`torch.compile` only support certain input types for namedtuple">
                <a href="/gb/gb0201">GB0201</a> —
                namedtuple construction
            </li>

            <li data-gbid="GB0202" data-type="non-const argument in nn.Module method" data-explanation="Dynamo does not support calling method `{name}` of ``nn.Module`` {module} with non-constant arguments.">
                <a href="/gb/gb0202">GB0202</a> —
                non-const argument in nn.Module method
            </li>

            <li data-gbid="GB0203" data-type="non-const keys in dict_keys" data-explanation="Dynamo expects dict_keys keys to be constants.">
                <a href="/gb/gb0203">GB0203</a> —
                non-const keys in dict_keys
            </li>

            <li data-gbid="GB0204" data-type="non-const keys in mappingproxy" data-explanation="Dynamo expects mappingproxy keys to be constants.">
                <a href="/gb/gb0204">GB0204</a> —
                non-const keys in mappingproxy
            </li>

            <li data-gbid="GB0205" data-type="proxy not set" data-explanation="Dynamo requires the autograd.Function context to be initialized with a proxy.">
                <a href="/gb/gb0205">GB0205</a> —
                proxy not set
            </li>

            <li data-gbid="GB0206" data-type="setattr() on Tensor.requires_grad" data-explanation="setattr() on Tensor.requires_grad not supported. Mutating requires_grad can introduce a new leaf from non-leaf or vice versa in the middle of the graph, which AOTAutograd does not currently know how to handle.">
                <a href="/gb/gb0206">GB0206</a> —
                setattr() on Tensor.requires_grad
            </li>

            <li data-gbid="GB0207" data-type="sort with non-constant keys" data-explanation="Cannot perform sort with non-constant key. First non-constant key type: {python_type}. Most notably, we cannot sort with Tensor or SymInt keys, but we can sort ints.">
                <a href="/gb/gb0207">GB0207</a> —
                sort with non-constant keys
            </li>

            <li data-gbid="GB0208" data-type="torch.* op returned non-Tensor" data-explanation="torch.* ops that return a non-Tensor cannot be traced into the Dynamo FX graph output">
                <a href="/gb/gb0208">GB0208</a> —
                torch.* op returned non-Tensor
            </li>

            <li data-gbid="GB0209" data-type="torch.autograd._unsafe_preserve_version_counter escaped from compiled region" data-explanation="Dynamo doesn't support compiling a region that returns a torch.autograd._unsafe_preserve_version_counter context manager.">
                <a href="/gb/gb0209">GB0209</a> —
                torch.autograd._unsafe_preserve_version_counter escaped from compiled region
            </li>

            <li data-gbid="GB0210" data-type="torch.distributed package is not available!" data-explanation="The PyTorch package doesn't include torch.distributed when building from source.">
                <a href="/gb/gb0210">GB0210</a> —
                torch.distributed package is not available!
            </li>

            <li data-gbid="GB0211" data-type="torch.nn.Module with a non-function custom __getattr__" data-explanation="Dynamo detected a nn.Module object with a custom `__getattr__` method, but this method is not a standard Python function (e.g., it might be implemented in C/C++). Dynamo cannot currently trace into such non-standard `__getattr__` methods.">
                <a href="/gb/gb0211">GB0211</a> —
                torch.nn.Module with a non-function custom __getattr__
            </li>

            <li data-gbid="GB0212" data-type="torch.profiler object escaped from compiled region" data-explanation="Dynamo doesn't support compiling a region that returns a torch.profiler context manager.">
                <a href="/gb/gb0212">GB0212</a> —
                torch.profiler object escaped from compiled region
            </li>

            <li data-gbid="GB0213" data-type="unimplemented builtin op on tensor arguments" data-explanation="Dynamo does not know how to trace builtin operator {self.fn} with tensor arguments">
                <a href="/gb/gb0213">GB0213</a> —
                unimplemented builtin op on tensor arguments
            </li>

            <li data-gbid="GB0214" data-type="unsupported SymNode comparison op" data-explanation="Dynamo does not support the comparison op {op.__name__} with SymNode arguments {left}, {right}">
                <a href="/gb/gb0214">GB0214</a> —
                unsupported SymNode comparison op
            </li>

            <li data-gbid="GB0215" data-type="unsupported Tensor comparison op" data-explanation="Dynamo does not support the comparison op {op.__name__} with Tensor arguments {left}, {right}">
                <a href="/gb/gb0215">GB0215</a> —
                unsupported Tensor comparison op
            </li>

            <li data-gbid="GB0216" data-type="unsupported grid type for triton hop check_grid" data-explanation="`torch.compile` only supports list-like grid for check_grid">
                <a href="/gb/gb0216">GB0216</a> —
                unsupported grid type for triton hop check_grid
            </li>

            <li data-gbid="GB0217" data-type="unsupported hasattr operation" data-explanation="msg">
                <a href="/gb/gb0217">GB0217</a> —
                unsupported hasattr operation
            </li>

            <li data-gbid="GB0218" data-type="unsupported index(Tensor)" data-explanation="Dynamo does not support tracing builtin index() on a Tensor">
                <a href="/gb/gb0218">GB0218</a> —
                unsupported index(Tensor)
            </li>

            <li data-gbid="GB0219" data-type="Backend compiler exception" data-explanation="Backend compiler `{name}` failed with {str(e)}. Adding a graph break.">
                <a href="/gb/gb0219">GB0219</a> —
                Backend compiler exception
            </li>

            <li data-gbid="GB0220" data-type="Failed to mutate tensor data attribute to different dtype" data-explanation="Dyanmo only supports mutating `.data` of tensor to a new one with the same dtype">
                <a href="/gb/gb0220">GB0220</a> —
                Failed to mutate tensor data attribute to different dtype
            </li>

            <li data-gbid="GB0221" data-type="non-generator contextlib.contextmanager" data-explanation="Cannot compile function decorated with `@contextlib.contextmanager` that is not a generator, i.e. does not use `yield`">
                <a href="/gb/gb0221">GB0221</a> —
                non-generator contextlib.contextmanager
            </li>

        </ul>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', () => {
            const searchInput = document.getElementById('search-input');
            const registryList = document.getElementById('registry-list');
            const listItems = Array.from(registryList.getElementsByTagName('li'));

            searchInput.addEventListener('input', (event) => {
                const query = event.target.value.toLowerCase();

                listItems.forEach(item => {
                    const gbid = item.getAttribute('data-gbid').toLowerCase();
                    const type = item.getAttribute('data-type').toLowerCase();
                    const explanation = item.getAttribute('data-explanation').toLowerCase();

                    if (gbid.includes(query) || type.includes(query) || explanation.includes(query)) {
                        item.style.display = ''; // Show item
                    } else {
                        item.style.display = 'none'; // Hide item
                    }
                });
            });
        });
    </script>
</body>
</html>
